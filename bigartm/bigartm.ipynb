{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import artm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "print(artm.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODELS_NUMBER = 3\n",
    "#all_colors = list(colors.cnames.keys())\n",
    "all_colors = ['red', 'green', 'blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizers = []\n",
    "dictionaries = []\n",
    "for i in range(MODELS_NUMBER):\n",
    "    vectorizers.append(\n",
    "        artm.BatchVectorizer(gather_dictionary=True, data_format='vowpal_wabbit', data_path='../rss_features.txt', target_folder=\"rss_batches\")\n",
    "    )\n",
    "    dictionaries.append(vectorizers[-1].dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(MODELS_NUMBER):\n",
    "    scores.append([\n",
    "        artm.SparsityPhiScore(name='SparsityPhiScore'),\n",
    "        artm.SparsityThetaScore(name='SparsityThetaScore'),\n",
    "        artm.TopTokensScore(name='TopTokensScore', num_tokens=20, dictionary=dictionaries[i], class_id='rss'),\n",
    "        artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.3, dictionary=dictionaries[i]),\n",
    "        artm.PerplexityScore(name='PerplexityScore', use_unigram_document_model=False, dictionary=dictionaries[i])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regularizers = [\n",
    "    [\n",
    "        artm.SmoothSparsePhiRegularizer(name='SmootSparsePhi', tau=0.5),\n",
    "        artm.SmoothSparseThetaRegularizer(name='SmootSparseTheta', tau=-0.15)\n",
    "    ],\n",
    "    [\n",
    "        artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=2)\n",
    "    ],\n",
    "    [\n",
    "        artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi')\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(MODELS_NUMBER):\n",
    "    models.append(\n",
    "        artm.ARTM(num_topics=30, cache_theta=True, scores=scores[i], regularizers=regularizers[i])\n",
    "    )\n",
    "    models[-1].initialize(dictionary=dictionaries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(MODELS_NUMBER):\n",
    "    models[i].fit_offline(batch_vectorizer=vectorizers[i], num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparsity_phi = []\n",
    "sparsity_theta = []\n",
    "kernel_kontrasts = []\n",
    "kernel_purity = []\n",
    "perplexity = []\n",
    "m_colors = []\n",
    "lines = []\n",
    "for i in range(MODELS_NUMBER):\n",
    "    sparsity_phi.append(models[i].score_tracker['SparsityPhiScore'].last_value)\n",
    "    sparsity_theta .append(models[i].score_tracker['SparsityThetaScore'].last_value)\n",
    "    kernel_kontrasts.append(models[i].score_tracker['TopicKernelScore'].last_average_contrast)\n",
    "    kernel_purity.append(models[i].score_tracker['TopicKernelScore'].last_average_purity)\n",
    "    perplexity.append(models[i].score_tracker['PerplexityScore'].last_value)\n",
    "    lines.append(range(models[i].num_phi_updates))\n",
    "    lines.append(models[i].score_tracker['PerplexityScore'].value)\n",
    "    lines.append(all_colors[i])\n",
    "    m_colors.append(all_colors[i])\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('ARTM perp. (red)')\n",
    "print('Sparsity Phi: {}'.format(sparsity_phi))\n",
    "print('Sparsity Theta: {}'.format(sparsity_theta))\n",
    "print('Kernel contrast: {}'.format(kernel_kontrasts))\n",
    "print('Kernel purity: {}'.format(kernel_purity))\n",
    "print('Perplexity: {}'.format(perplexity))\n",
    "print('Colors: {}'.format(m_colors))\n",
    "plt.plot(*lines, linewidth=1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "m_colors = []\n",
    "for i in range(MODELS_NUMBER):\n",
    "    lines.append(range(models[i].num_phi_updates))\n",
    "    lines.append(models[i].score_tracker['SparsityPhiScore'].value)\n",
    "    lines.append(all_colors[i])\n",
    "    m_colors.append(all_colors[i])\n",
    "print('Colors: {}'.format(m_colors))\n",
    "plt.plot(*lines, linewidth=2)\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('ARTM Phi sparsity')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "lines = []\n",
    "m_colors = []\n",
    "for i in range(MODELS_NUMBER):\n",
    "    lines.append(range(models[i].num_phi_updates))\n",
    "    lines.append(models[i].score_tracker['SparsityThetaScore'].value)\n",
    "    lines.append(all_colors[i])\n",
    "    m_colors.append(all_colors[i])\n",
    "print('Colors: {}'.format(m_colors))\n",
    "plt.plot(*lines, linewidth=2)\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('ARTM Phi sparsity')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for topic_name in models[0].topic_names:\n",
    "    print topic_name, ':'\n",
    "    for i in range(MODELS_NUMBER):\n",
    "        print 'model_{}: '.format(i),\n",
    "        for token in models[i].score_tracker['TopTokensScore'].last_tokens[topic_name]:\n",
    "            print token, ',',\n",
    "        print('\\n')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2ml",
   "language": "python",
   "name": "py2ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
